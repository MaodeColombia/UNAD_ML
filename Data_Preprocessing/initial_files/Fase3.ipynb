{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWo7n_hXJWvj"
   },
   "source": [
    "# FASE 3 - MACHINE LEARNING\n",
    "\n",
    "\n",
    "## Preparación de los datos\n",
    "\n",
    "### Tipos de datos: numéricos, categóricos, texto, imágenes, etc.\n",
    "\n",
    "Los datos pueden ser de muchos tipos diferentes, entre ellos:\n",
    "\n",
    "- **Datos numéricos**: mediciones de temperatura, tiempo, altura, etc.\n",
    "- **Datos categóricos** especie de un animal, la categoría de un producto, etc.\n",
    "- **Texto**: comentarios de usuarios en una red social, las reseñas de productos en una tienda en línea, etc.\n",
    "- **Imágenes**: fotografías, escaneos de documentos, etc.\n",
    "\n",
    "### Limpieza y preprocesamiento de datos\n",
    "\n",
    "Antes de utilizar los datos para entrenar un modelo, es necesario realizar una serie de pasos para limpiar y preprocesar los datos:\n",
    "\n",
    "- **Limpieza de datos**: identificar y eliminar valores atípicos, datos faltantes, etc.\n",
    "- **Transformación de datos**: convertir los datos a un formato adecuado para el modelo. Por ejemplo, convertir datos categóricos a numéricos, normalizar los datos numéricos, etc.\n",
    "- **Selección de características**: seleccionar las características más relevantes para el modelo y eliminar aquellas que no aportan información útil.\n",
    "\n",
    "### Separación de datos en entrenamiento y prueba\n",
    "\n",
    "Para evaluar el rendimiento del modelo, es necesario separar los datos en un conjunto de entrenamiento y un conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_F2FTIdMJ8Eb"
   },
   "source": [
    "# Ejemplo de código para la limpieza de datos utilizando Pandas\n",
    "\n",
    "Este código realiza varias tareas comunes de limpieza de datos, como eliminar duplicados, eliminar filas con valores faltantes, convertir tipos de datos, eliminar columnas innecesarias y reemplazar valores. También muestra cómo filtrar filas basadas en una condición y guardar los datos limpios en un archivo CSV.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e55mgKkuW1y6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "nYJMTGE8J3dV",
    "outputId": "35adbe30-23ae-485e-a132-911fb72f7a0f"
   },
   "outputs": [],
   "source": [
    "# Carga los datos en un dataframe de Pandas\n",
    "df = pd.read_csv('MORBILIDAD_EN_EL_SERVICIO_DE_URGENCIAS1.csv')\n",
    "\n",
    "#Contenido de la base de datos\n",
    "df.info()\n",
    "df.drop_duplicates\n",
    "\n",
    "#Elimina columnas donde hay al menos un valor faltante\n",
    "df1=df.dropna(axis='columns')\n",
    "df1\n",
    "#Elimina la fila de ídice 5\n",
    "df2=df1.drop([5])\n",
    "df2\n",
    "\n",
    "\n",
    "# Filtrar filas basadas en una condición\n",
    "#df = df[df['columna8'] > 10]\n",
    "\n",
    "# Guardar los datos limpios en un archivo CSV\n",
    "df.to_csv('datos_limpio.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"PROCEDENCIA\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostico = df[\"NOMBRE_DIAGNOSTICO\"].value_counts()\n",
    "diagnostico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "subset = diagnostico.head()\n",
    "sns.barplot(y=subset.index, x=subset.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df2[\"NOMBRE_DIAGNOSTICO\"])\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df2[\"PROCEDENCIA\"])\n",
    "\n",
    "list(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhvFSuEFJy5H"
   },
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en los conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Entrenar el modelo con el mejor valor de k\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una predicción con los datos de prueba. (calcula sus vecinos más cercanos en el conjunto de entrenamiento)\n",
    "print(\"Test de predicción: {}\".format(knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precisión del modelo\n",
    "print(\"Test de precisción: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva entrada\n",
    "nuevo_diagnostico = \"DOLOR ABDOMINNAL\"\n",
    "\n",
    "# Transformamos la entrada en un vector de características\n",
    "nuevo_X = vectorizer.transform([nuevo_diagnostico])\n",
    "\n",
    "# Predección\n",
    "pred_Y = knn.predict(nuevo_X)\n",
    "\n",
    "# Decodificar la procedencia\n",
    "pred_procedencia = encoder.inverse_transform(pred_Y)\n",
    "\n",
    "print(f\"La procedencia del paciente con {nuevo_diagnostico} es {pred_procedencia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision= []\n",
    "test_precision = []\n",
    "#  n_neighbors desde 1 a 10 \n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # contrucción del modelo\n",
    "    kinn = KNeighborsClassifier(n_neighbors=n_neighbors) \n",
    "    kinn.fit(X_train, y_train)\n",
    "    # Guardado de las precisiones \n",
    "    precision.append(kinn.score(X_train, y_train))\n",
    "    # Guardado general \n",
    "    test_precision.append(kinn.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, precision, label=\"presición del modelo entrendado\")\n",
    "plt.plot(neighbors_settings, test_precision, label=\"precisión conjunto de prueba\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos lineales\n",
    "\n",
    "$$\\hat{y} = \\hat{\\beta}_0+\\hat{\\beta}_1x_1 + \\hat{\\beta}_2x_2 + \\hat{\\beta}_3 x_3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Datos de entreada con tres caraterísticas \n",
    "X = np.array([[1, 1, 4], [1, 2, 3], [2, 2, 5], [2, 3, 6]])\n",
    "y = np.dot(X, np.array([4, 2, -1]))\n",
    "\n",
    "rl = LinearRegression().fit(X, y)\n",
    "\n",
    "\n",
    "print(\"lr.coef_: {}\".format(rl.coef_))\n",
    "print(\"lr.intercept_: {}\".format(rl.intercept_))\n",
    "\n",
    "#rl.predict(np.array([[3, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "# Prepare arrays x, y, z\n",
    "z = X[:,2]\n",
    "x = X[:,0]\n",
    "y = X[:,1]\n",
    "\n",
    "ax.plot(x, y, z, 'o',label='Datos')\n",
    "ax.legend()\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos no lineales\n",
    "\n",
    "Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "print(\"cancer.keys(): \\n{}\".format(cancer.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    stratify=cancer.target, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "plt.hlines(0, 0, cancer.data.shape[1])\n",
    "plt.xlabel(\"Índice de Coeficientes\")\n",
    "plt.ylabel(\"Tamaño del Coeficiente\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gael Varoquaux\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "# Generate a toy dataset, it's just a straight line with some Gaussian noise:\n",
    "xmin, xmax = -5, 5\n",
    "n_samples = 100\n",
    "np.random.seed(0)\n",
    "X = np.random.normal(size=n_samples)\n",
    "y = (X > 0).astype(float)\n",
    "X[X > 0] *= 4\n",
    "X += 0.3 * np.random.normal(size=n_samples)\n",
    "\n",
    "X = X[:, np.newaxis]\n",
    "\n",
    "# Fit the classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# and plot the result\n",
    "plt.scatter(X.ravel(), y, label=\"datos\", color=\"black\", zorder=20)\n",
    "X_test = np.linspace(-5, 10, 300)\n",
    "loss = expit(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "plt.plot(X_test, loss, label=\"Logistic Regression Model\", color=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    stratify=cancer.target, random_state=42)\n",
    "tree = DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names, impurity=False, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
